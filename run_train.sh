#!/bin/bash

# ================= é…ç½®åŒºåŸŸ =================
# âœ… ä½¿ç”¨4å¼ ç©ºé—²çš„GPU (2, 4, 6, 7) åˆ†æ•£æ¨¡åž‹è´Ÿè½½
# è¿™äº›GPUç›¸å¯¹ç©ºé—²ï¼ˆçº¦1.6 GBå ç”¨ï¼‰ï¼Œå¯ä»¥åˆ†æ•£æ¨¡åž‹åˆ°å¤šå¼ å¡ä¸Š
export CUDA_VISIBLE_DEVICES=2,4,6,7

# [å†…å­˜ä¼˜åŒ–] å‡å°‘å†…å­˜ç¢Žç‰‡åŒ–
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

# é¡¹ç›®è·¯å¾„é…ç½®
BIRD_ROOT="/data/cuishuai/datasets/text-to-sql/BIRD-SQL"
OUTPUT_DIR="./checkpoints_deepseek_rt_4bit" # æ”¹ååŒºåˆ†

# ... (å…¶ä½™é…ç½®ä¿æŒä¸å˜) ...
MODEL_PATH="deepseek-ai/DeepSeek-Coder-V2-Lite-Base"
TEXT_EMBED_DIM=2048
RT_CHANNELS=1024
RT_LAYERS=8
EPOCHS=10
LR=5e-5
GRAD_ACC_STEPS=32 

# ================= å¯åŠ¨å‘½ä»¤ =================
echo "ðŸš€ Starting DeepSeek-RT Training on 4 GPUs (2,4,6,7) with 4-bit Quantization..."
echo "   ðŸ“Š Model will be distributed across multiple GPUs to reduce memory pressure"
# ... (å…¶ä½™ä¿æŒä¸å˜) ...
python -u train_bird_sql.py \
    --bird_root "$BIRD_ROOT" \
    --model_path "$MODEL_PATH" \
    --output_dir "$OUTPUT_DIR" \
    --model_type "$MODEL_PATH" \
    --channels $RT_CHANNELS \
    --num_layers $RT_LAYERS \
    --dropout 0.1 \
    --text_embed_dim $TEXT_EMBED_DIM \
    --epochs $EPOCHS \
    --lr $LR \
    --grad_acc_steps $GRAD_ACC_STEPS \
    --save_limit 3 \
    2>&1 | tee train_log.txt

echo "ðŸŽ‰ Training finished! Logs saved to train_log.txt"